import os
import gdown
import tensorflow as tf
import zipfile
import gradio as gr
from transformers import BertTokenizer, TFBertForSequenceClassification
from deep_translator import GoogleTranslator

MODEL_DIR = "."
ZIP_PATH = "assets.zip"
DOWNLOAD_URL = "https://drive.google.com/uc?export=download&id=1kIrOwZfT4zqXjZQvVdRobCUDAt-wA4bR"

# -------------------------
# ØªØ­Ù…ÙŠÙ„ ÙˆÙÙƒ Ø§Ù„Ø¶ØºØ· Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
# -------------------------
def setup_model():
    if not os.path.exists("tf_model.h5"):
        print("ğŸ”½ Downloading model...")
        gdown.download(DOWNLOAD_URL, ZIP_PATH, quiet=False)
        print("âœ… Download complete.")

        print("ğŸ“¦ Extracting model...")
        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
            zip_ref.extractall()
        print("âœ… Extraction done.")

        os.remove(ZIP_PATH)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„ØªÙˆÙƒÙ†ÙŠØ²Ø±
setup_model()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„ØªÙˆÙƒÙ†ÙŠØ²Ø±
model = TFBertForSequenceClassification.from_pretrained(MODEL_DIR)
tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)
labels = ["happy", "sad", "angry", "normal"]

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤
def predict(text):
    try:
        translated_text = GoogleTranslator(source='auto', target='en').translate(text)
    except Exception as e:
        return f"Translation failed: {str(e)}"
    
    inputs = tokenizer(translated_text, return_tensors="tf", truncation=True, padding=True)
    outputs = model(**inputs)
    logits = outputs.logits
    predicted_class = tf.argmax(logits, axis=1).numpy()[0]
    sentiment = labels[predicted_class]

    return {
        "original_text": text,
        "translated_text": translated_text,
        "sentiment": sentiment,
        "label_index": int(predicted_class),
        "logits": logits.numpy().tolist()
    }

# ÙˆØ§Ø¬Ù‡Ø© Gradio
iface = gr.Interface(fn=predict, inputs="text", outputs="json")

iface.launch(share=True)  # share=True Ù‡ÙŠØ³Ù…Ø­Ù„Ùƒ Ø¨Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø¹Ø§Ù…
